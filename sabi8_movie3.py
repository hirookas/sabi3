# sabi8_movie3.py
# -*- coding: utf-8 -*-

import os
import io
import time
import json
import math
import numpy as np
import torch
import torch.nn as nn
import streamlit as st
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw
from torchvision import transforms, models
from matplotlib import rcParams, font_manager
from matplotlib.font_manager import FontProperties

# --- å‹•ç”»ç”¨ï¼ˆOpenCVã¯ä»»æ„ã€‚ç„¡ã„å ´åˆã¯å‹•ç”»ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ãˆã¾ã›ã‚“ï¼‰ ---
try:
    import cv2
except Exception:
    cv2 = None

# =========================================================
# é€æ˜faviconï¼ˆè‡ªè»¢è»Šã‚¢ã‚¤ã‚³ãƒ³å®Œå…¨éè¡¨ç¤ºï¼‰ã‚’ç”¨æ„ï¼ˆãªã‘ã‚Œã°ç”Ÿæˆï¼‰
# =========================================================
FAVICON = "transparent.png"
def ensure_transparent_favicon(path=FAVICON):
    if not os.path.exists(path):
        try:
            img = Image.new("RGBA", (1, 1), (0, 0, 0, 0))
            img.save(path)
        except Exception:
            pass
ensure_transparent_favicon()

# =========================================================
# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆã“ã®1å›ã ã‘ã«ã™ã‚‹ï¼‰
# =========================================================
st.set_page_config(
    page_title="é‡‘å±è…é£Ÿè¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon=FAVICON,
    layout="wide",
    menu_items={"Get Help": None, "Report a bug": None, "About": None}
)

# =========================================================
# å³ä¸Šã®è‡ªè»¢è»Š/ãƒ©ãƒ³ãƒŠãƒ¼ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ï¼‰ã‚’ã“ã®ã‚¢ãƒ—ãƒªã ã‘æ¶ˆã™
# =========================================================
st.markdown("""
<style>
[data-testid="stStatusWidget"] { display: none !important; }
header [data-testid="stStatusWidget"] { display: none !important; }
.block-container img, .block-container canvas, .block-container svg {
  max-width: 100% !important;
  height: auto !important;
}
.section-gap { margin-top: 24px; }
</style>
""", unsafe_allow_html=True)

# =========================================================
# èµ·å‹•ä¸­ã¯ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ã¿è¡¨ç¤º â†’ çµ‚äº†å¾Œã¯éè¡¨ç¤ºã«ã—ã¦æœ¬ä½“ã¸
# =========================================================
if "initialized" not in st.session_state:
    st.session_state.initialized = False
if not st.session_state.initialized:
    progress = st.progress(0)
    for i in range(100):
        time.sleep(0.01)
        progress.progress(i + 1)
    st.session_state.initialized = True
    st.rerun()

# =========================================================
# ä»¥é™ï¼šã‚¢ãƒ—ãƒªæœ¬ä½“
# =========================================================

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ ---
_JP_FONT_CANDIDATES = [
    "IPAexGothic", "IPAGothic",
    "Noto Sans CJK JP", "Noto Sans JP",
    "Hiragino Sans", "Hiragino Kaku Gothic ProN",
    "Yu Gothic", "Meiryo",
]
def set_japanese_font():
    found = None
    for fam in _JP_FONT_CANDIDATES:
        try:
            fp = FontProperties(family=fam)
            path = font_manager.findfont(fp, fallback_to_default=False)
            if path and os.path.exists(path):
                found = fam
                break
        except Exception:
            pass
    if found:
        rcParams["font.family"] = found
    rcParams["axes.unicode_minus"] = False
set_japanese_font()

st.title("é‡‘å±è…é£Ÿè¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ ")

# -------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ --------
def fit_square_canvas(img: Image.Image, size_px: int, bg=(255, 255, 255), inner_ratio: float = 0.85):
    inner_ratio = max(0.1, min(1.0, float(inner_ratio)))
    if img.mode != "RGB":
        img = img.convert("RGB")
    w, h = img.size
    max_side = int(size_px * inner_ratio)
    scale = min(max_side / w, max_side / h)
    new_w, new_h = max(1, int(w * scale)), max(1, int(h * scale))
    resized = img.resize((new_w, new_h), Image.LANCZOS)
    canvas = Image.new("RGB", (size_px, size_px), color=bg)
    off_x = (size_px - new_w) // 2
    off_y = (size_px - new_h) // 2
    canvas.paste(resized, (off_x, off_y))
    return canvas

def draw_red_border(img: Image.Image, width: int = 4, color=(255, 0, 0)) -> Image.Image:
    bordered = img.copy()
    draw = ImageDraw.Draw(bordered)
    w, h = bordered.size
    draw.rectangle([(1, 1), (w - 2, h - 2)], outline=color, width=width)
    return bordered

def make_square_bar_figure(
    labels, values, size_px: int,
    title: str = "", red_border: bool = False,
    hatch_pattern: str | None = None, hatch_facecolor=None
):
    dpi = 100
    size_in = size_px / dpi
    fig, ax = plt.subplots(figsize=(size_in, size_in), dpi=dpi)
    bars = ax.bar(labels, values)
    ax.set_ylim(0, 1)
    if title:
        ax.set_title(title, fontsize=11, pad=6)
    for i, v in enumerate(values):
        ax.text(i, min(0.98, v + 0.03), f"{v:.2f}", ha='center', fontsize=9)
    ax.grid(axis="y", linestyle="--", alpha=0.25)
    if hatch_pattern is not None:
        for b in bars:
            if hatch_facecolor is not None:
                b.set_facecolor(hatch_facecolor)
            b.set_hatch(hatch_pattern)
    if red_border:
        for s in ax.spines.values():
            s.set_edgecolor("red")
            s.set_linewidth(3)
    plt.tight_layout()
    return fig

# -------- è‡ªå‹•æ¤œå‡ºï¼šãƒ¢ãƒ‡ãƒ«/ç”»åƒ/å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå€™è£œ --------
MODEL_EXTS = (".pth", ".pt", ".bin")
IMAGE_EXTS = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")
VIDEO_EXTS = (".mp4", ".mov", ".avi", ".mkv", ".webm")

def walk_dirs_with_files(roots, want_exts, max_depth=2, limit=200):
    seen, out = set(), []
    cwd = os.path.abspath(".")
    for base in roots:
        if not os.path.isdir(base):
            continue
        base_abs = os.path.abspath(base)
        for dirpath, dirnames, filenames in os.walk(base_abs):
            rel = os.path.relpath(dirpath, base_abs)
            depth = 0 if rel == "." else rel.count(os.sep) + 1
            if depth > max_depth:
                dirnames[:] = []
                continue
            if any(str(f).lower().endswith(want_exts) for f in filenames):
                rel_to_cwd = os.path.relpath(dirpath, cwd)
                norm = os.path.normpath(rel_to_cwd)
                if norm not in seen:
                    seen.add(norm)
                    out.append(norm)
                    if len(out) >= limit:
                        return sorted(out)
    return sorted(out)

SEARCH_ROOTS = [
    ".", "saved_models", "models", "weights", "checkpoints",
    "sample", "samples", "images", "dataset",
]
VIDEO_SEARCH_ROOTS = ["movie", "movies", "video", "videos", "."]

# -------- ãƒ¢ãƒ‡ãƒ«å®šç¾©ãƒ»å‰å‡¦ç† --------
class CustomResNet18(nn.Module):
    def __init__(self, base_model, num_classes):
        super(CustomResNet18, self).__init__()
        self.features = nn.Sequential(*list(base_model.children())[:-1])
        self.fc_class = nn.Linear(base_model.fc.in_features, num_classes)  # 3åˆ†é¡
        self.fc_regression = nn.Linear(base_model.fc.in_features, 1)       # å›å¸°(0-1)
        self.sigmoid = nn.Sigmoid()  # å›å¸°å‡ºåŠ›ã‚’0ã€œ1ã«
    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        class_logits = self.fc_class(x)
        regression_output = self.sigmoid(self.fc_regression(x))
        return class_logits, regression_output

# ãƒ©ãƒ™ãƒ«åï¼ˆå†…éƒ¨è¡¨ç¾ï¼‰
class_names = ["Corrosion", "no-Corrosion", "base"]

def to_display_name(label: str) -> str:
    # è¡¨ç¤ºå: base -> "new"
    low = label.strip().lower()
    if low in ("base",):
        return "new"
    if low in ("no-corrosion", "no-corossion"):
        return "no-corrosion"
    if low in ("corrosion",):
        return "corrosion"
    return label

def norm_label(s: str) -> str:
    return s.lower().replace("_", "-").replace(" ", "")

@st.cache_resource
def load_model(path, num_classes=3):
    try:
        base_model = models.resnet18(weights=None)
    except TypeError:
        base_model = models.resnet18(pretrained=False)
    model = CustomResNet18(base_model, num_classes)
    state = torch.load(path, map_location="cpu")
    model.load_state_dict(state)
    model.eval()
    return model

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

def infer_image(model, image: Image.Image):
    input_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        class_logits, regression_output = model(input_tensor)
        logits = class_logits.squeeze().numpy()                # (3,)
        class_scores = torch.softmax(class_logits, dim=1).squeeze().numpy()  # (3,)
        predicted_class = int(torch.argmax(class_logits, 1).item())
        regression_value = float(regression_output.item())     # 0-1
    return logits, class_scores, predicted_class, regression_value

# -------- è¿½åŠ ï¼šä¸­å¤®ãƒˆãƒªãƒŸãƒ³ã‚°ï¼ˆæ¨ªæ–¹å‘ã®ä»»æ„å‰²åˆï¼‰ --------
def crop_center_horizontal_fraction(img: Image.Image, fraction: float = 1/3) -> Image.Image:
    """ç”»åƒã®æ¨ªå¹…ã®ä¸­å¤® fraction(0-1) ã‚’åˆ‡ã‚Šå‡ºã™ï¼ˆé«˜ã•ã¯å…¨åŸŸï¼‰"""
    f = max(0.05, min(1.0, float(fraction)))
    w, h = img.size
    crop_w = max(1, int(round(w * f)))
    left = max(0, int(round((w - crop_w) / 2)))
    right = min(w, left + crop_w)
    if right <= left:
        return img
    return img.crop((left, 0, right, h))

# -------- è¿½åŠ ï¼šãƒãƒ¼ãƒ«æ¤œå‡ºï¼ˆç›´ç·š+è§’åº¦ï¼‰ï¼å›è»¢è£œæ­£ä»˜ãåˆ‡ã‚Šå‡ºã— --------
def _pil_to_cv_gray(pil_img: Image.Image, resize_max_w: int | None = 960):
    """PILâ†’OpenCV Grayï¼ˆå¹…ã‚’æŠ‘ãˆã¦é«˜é€ŸåŒ–ãƒ»åº§æ¨™ã¯å¾Œã§æˆ»ã™ï¼‰"""
    if cv2 is None:
        return None, None, None
    rgb = np.array(pil_img.convert("RGB"))
    h, w = rgb.shape[:2]
    scale = 1.0
    if resize_max_w is not None and w > resize_max_w:
        scale = resize_max_w / float(w)
        new_w = int(round(w * scale))
        new_h = int(round(h * scale))
        rgb_small = cv2.resize(rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)
    else:
        rgb_small = rgb
    gray = cv2.cvtColor(rgb_small, cv2.COLOR_RGB2GRAY)
    return gray, rgb_small, scale

def detect_pole_line(pil_img: Image.Image,
                     angle_tol_deg: float = 25.0,
                     min_length_ratio: float = 0.35,
                     canny1: int = 60, canny2: int = 180,
                     hough_thresh: int = 60,
                     max_line_gap_px: int = 10,
                     resize_max_w: int | None = 960):
    """
    ç›´ç«‹ã«è¿‘ã„ç›´ç·šï¼ˆè§’åº¦ ~ 90Â±angle_tol_degï¼‰ã‚’HoughLinesPã§æ¤œå‡ºã€‚
    æœ€é•·ã®ç·šåˆ†ã®ç«¯ç‚¹(x1,y1,x2,y2)ã¨ *ç¬¦å·ä»˜ã* è§’åº¦degï¼ˆatan2ãƒ™ãƒ¼ã‚¹ã€0=æ°´å¹³,90=å‚ç›´ï¼‰ã‚’è¿”ã™ã€‚
    è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°Noneã€‚
    """
    if cv2 is None:
        return None
    gray, _, scale = _pil_to_cv_gray(pil_img, resize_max_w=resize_max_w)
    if gray is None:
        return None
    h_s, w_s = gray.shape[:2]
    min_len_px = int(max(1, min_length_ratio * h_s))

    edges = cv2.Canny(gray, canny1, canny2)
    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=hough_thresh,
                            minLineLength=min_len_px, maxLineGap=max_line_gap_px)
    if lines is None or len(lines) == 0:
        return None

    best = None  # (length, (x1,y1,x2,y2, angle_deg_signed))
    for l in lines:
        x1, y1, x2, y2 = l[0]
        dx, dy = (x2 - x1), (y2 - y1)
        length = math.hypot(dx, dy)
        if length < min_len_px:
            continue
        angle_deg_signed = math.degrees(math.atan2(dy, dx))  # -180..180, 0=æ°´å¹³, 90=å‚ç›´
        if 90 - angle_tol_deg <= abs(angle_deg_signed) <= 90 + angle_tol_deg:
            if (best is None) or (length > best[0]):
                best = (length, (x1, y1, x2, y2, angle_deg_signed))

    if best is None:
        return None

    # å…ƒã‚µã‚¤ã‚ºã¸æˆ»ã™
    _, (x1, y1, x2, y2, angle_deg_signed) = best
    if scale != 0:
        inv = 1.0 / scale
        x1, y1, x2, y2 = int(round(x1*inv)), int(round(y1*inv)), int(round(x2*inv)), int(round(y2*inv))
    return (x1, y1, x2, y2, angle_deg_signed)

def _rotate_cv_keep_bounds(rgb: np.ndarray, angle_deg: float, border_value=(255, 255, 255)):
    """ç”»åƒä¸­å¿ƒå›ã‚Šã«å›è»¢ã—ã€åˆ‡ã‚Œãªã„ã‚ˆã†æ–°ã‚µã‚¤ã‚ºã«æ‹¡å¼µã—ã¦è¿”ã™ï¼ˆå›è»¢å¾Œç”»åƒ, 2x3ã‚¢ãƒ•ã‚£ãƒ³è¡Œåˆ—Mï¼‰ã€‚"""
    (h, w) = rgb.shape[:2]
    c = (w/2.0, h/2.0)
    M = cv2.getRotationMatrix2D(c, angle_deg, 1.0)  # OpenCVã¯+è§’åº¦ã§åæ™‚è¨ˆå›ã‚Š

    cos = abs(M[0, 0]); sin = abs(M[0, 1])
    new_w = int(h * sin + w * cos)
    new_h = int(h * cos + w * sin)

    # ä¸­å¿ƒãŒãšã‚Œãªã„ã‚ˆã†å¹³è¡Œç§»å‹•ã‚’åŠ ãˆã‚‹
    M[0, 2] += (new_w/2.0) - c[0]
    M[1, 2] += (new_h/2.0) - c[1]

    rotated = cv2.warpAffine(rgb, M, (new_w, new_h), flags=cv2.INTER_LINEAR, borderValue=border_value)
    return rotated, M

def _apply_affine_to_points(M, pts_xy):
    """2x3ã‚¢ãƒ•ã‚£ãƒ³Mã‚’ç‚¹ç¾¤(Nx2)ã«é©ç”¨ã—ã€å›è»¢å¾Œåº§æ¨™ã‚’è¿”ã™"""
    pts = np.asarray(pts_xy, dtype=np.float32)
    ones = np.ones((pts.shape[0], 1), dtype=np.float32)
    pts_h = np.concatenate([pts, ones], axis=1)   # Nx3
    out = (M @ pts_h.T).T                         # Nx2
    return out

def crop_to_pole_deskew(pil_img: Image.Image, width_fraction: float = 0.33, **detect_kwargs) -> Image.Image | None:
    """
    ãƒãƒ¼ãƒ«ç·šã‚’æ¤œå‡ºâ†’ãã®è§’åº¦ã ã‘ç”»åƒã‚’å›è»¢è£œæ­£â†’å›è»¢å¾Œã®ç·šã®xä¸­å¿ƒã‚’åŸºæº–ã«æ¨ªæ–¹å‘å¹…fractionã§åˆ‡ã‚Šå‡ºã—ã€‚
    å¤±æ•—ã—ãŸã‚‰Noneã€‚
    """
    if cv2 is None:
        return None
    res = detect_pole_line(pil_img, **detect_kwargs)
    if res is None:
        return None
    x1, y1, x2, y2, ang = res
    # ang(åº¦)ã‚’ 90 åº¦ã¸åˆã‚ã›ã‚‹å›è»¢é‡ï¼ˆä¾‹ï¼šang=76 -> +14åº¦å›è»¢ï¼‰
    rot_deg = 90.0 - ang

    rgb = np.array(pil_img.convert("RGB"))
    rotated, M = _rotate_cv_keep_bounds(rgb, rot_deg, border_value=(255, 255, 255))

    # ç·šã®ç«¯ç‚¹ã‚’å›è»¢å¾Œåº§æ¨™ã¸å¤‰æ›ã—ã€ä¸­å¿ƒxã‚’å¾—ã‚‹
    pts_rot = _apply_affine_to_points(M, np.array([[x1, y1], [x2, y2]], dtype=np.float32))
    cx = float(pts_rot[:, 0].mean())

    # å›è»¢å¾Œç”»åƒã§æ¨ªæ–¹å‘ã«å¹…fractionã‚’åˆ‡ã‚Šå‡ºã—
    f = max(0.05, min(1.0, float(width_fraction)))
    H, W = rotated.shape[:2]
    crop_w = max(1, int(round(W * f)))
    left = int(round(cx - crop_w/2))
    right = left + crop_w
    if left < 0:
        right -= left; left = 0
    if right > W:
        left -= (right - W); right = W; left = max(0, left)
    if right <= left:
        return None

    roi = rotated[:, left:right, :]
    return Image.fromarray(roi)

def detect_pole_center_x(pil_img: Image.Image,
                         angle_tol_deg: float = 12.0,
                         min_length_ratio: float = 0.35,
                         canny1: int = 60, canny2: int = 180,
                         hough_thresh: int = 60,
                         max_line_gap_px: int = 10,
                         resize_max_w: int | None = 960) -> int | None:
    """ï¼ˆå›è»¢è£œæ­£ãªã—ç‰ˆï¼‰ç¸¦ç·šã®ä¸­å¿ƒxåº§æ¨™ã®ã¿è¿”ã™ã€‚"""
    res = detect_pole_line(pil_img, angle_tol_deg, min_length_ratio, canny1, canny2,
                           hough_thresh, max_line_gap_px, resize_max_w)
    if res is None:
        return None
    x1, y1, x2, y2, _ = res
    cx_full = int(round((x1 + x2) / 2.0))
    cx_full = int(np.clip(cx_full, 0, pil_img.size[0]-1))
    return cx_full

def crop_to_pole(pil_img: Image.Image, width_fraction: float = 0.33, **detect_kwargs) -> Image.Image | None:
    """ï¼ˆå›è»¢è£œæ­£ãªã—ç‰ˆï¼‰æ¤œå‡ºxä¸­å¿ƒã‚’åŸºã«æ¨ªæ–¹å‘ã®ã¿å¹…fractionã§åˆ‡ã‚Šå‡ºã™ã€‚"""
    cx = detect_pole_center_x(pil_img, **detect_kwargs)
    if cx is None:
        return None
    f = max(0.05, min(1.0, float(width_fraction)))
    w, h = pil_img.size
    crop_w = max(1, int(round(w * f)))
    left = int(round(cx - crop_w / 2))
    right = left + crop_w
    if left < 0:
        right -= left; left = 0
    if right > w:
        left -= (right - w); right = w; left = max(0, left)
    if right <= left:
        return None
    return pil_img.crop((left, 0, right, h))

# -------- å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ --------
with st.sidebar:
    st.header("è¡¨ç¤º/å‡ºåŠ›è¨­å®š")
    INPUT_MODE = st.radio("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿", ["ç”»åƒãƒ•ã‚©ãƒ«ãƒ€", "å‹•ç”»ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼‰"], index=0)
    TILE_SIZE = st.slider("ã‚¿ã‚¤ãƒ«é«˜ã•ï¼ˆpxï¼‰", 200, 540, 320, step=10)
    IMAGE_SHRINK = st.slider("ç”»åƒã®ç¸®å°ç‡ï¼ˆå†…å´ã«ä½™ç™½ï¼‰", 0.60, 1.00, 0.85, 0.01)
    regression_mode = st.selectbox("å›å¸°ã®æ„å‘³", ["åŠ£åŒ–åº¦ã‚¹ã‚³ã‚¢ (0-1)", "è…é£Ÿé¢ç©ç‡ (0-1)"])
    layout_mode = st.radio("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ", ["3åˆ—ï¼ˆç”»åƒ+åˆ†é¡+å›å¸°ï¼‰", "2åˆ—ï¼ˆç”»åƒ+å›³ï¼‰"], index=0)

    if INPUT_MODE.startswith("å‹•ç”»"):
        if cv2 is None:
            st.error("å‹•ç”»å‡¦ç†ã«ã¯ OpenCV ãŒå¿…è¦ã§ã™ã€‚`pip install opencv-python` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        FRAME_EVERY_SEC = st.slider("ãƒ•ãƒ¬ãƒ¼ãƒ é–“éš”ï¼ˆç§’ï¼‰", 0.5, 10.0, 2.0, 0.5)
        MAX_FRAMES_PER_VIDEO = st.number_input("æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ /å‹•ç”»", min_value=1, max_value=2000, value=200, step=10)

        # â˜… åˆ‡ã‚Šå‡ºã—ãƒ¢ãƒ¼ãƒ‰ã«ã€Œãƒãƒ¼ãƒ«è‡ªå‹•ï¼‹å›è»¢è£œæ­£ã€ã‚’è¿½åŠ 
        CROP_MODE_VIDEO = st.radio("ãƒ•ãƒ¬ãƒ¼ãƒ åˆ‡ã‚Šå‡ºã—æ–¹æ³•", ["ãªã—", "ä¸­å¤®", "ãƒãƒ¼ãƒ«è‡ªå‹•", "ãƒãƒ¼ãƒ«è‡ªå‹•ï¼‹å›è»¢è£œæ­£"], index=3)
        if CROP_MODE_VIDEO == "ä¸­å¤®":
            CENTER_CROP_FRACTION = st.slider("ä¸­å¤®ãƒˆãƒªãƒŸãƒ³ã‚°å¹…ï¼ˆæ¨ªå‰²åˆï¼‰", 0.10, 1.00, 0.33, 0.01)
        else:
            CENTER_CROP_FRACTION = 1.0  # extractorã§ã¯ã‚¯ãƒ­ãƒƒãƒ—ã—ãªã„

        if CROP_MODE_VIDEO in ("ãƒãƒ¼ãƒ«è‡ªå‹•", "ãƒãƒ¼ãƒ«è‡ªå‹•ï¼‹å›è»¢è£œæ­£"):
            POLE_CROP_FRACTION = st.slider("ãƒãƒ¼ãƒ«åˆ‡ã‚Šå‡ºã—å¹…ï¼ˆæ¨ªå‰²åˆï¼‰", 0.10, 1.00, 0.33, 0.01)
            with st.expander("ãƒãƒ¼ãƒ«æ¤œå‡ºã®è©³ç´°è¨­å®š", expanded=False):
                ANG_TOL = st.slider("å‚ç›´ã¨ã¿ãªã™è§’åº¦Â±ï¼ˆåº¦ï¼‰", 5, 40, 25, 1)
                MIN_LEN_RATIO = st.slider("æœ€å°ç¸¦ç·šé•·ï¼ˆç”»åƒé«˜ã•æ¯”ï¼‰", 0.10, 0.90, 0.35, 0.05)
                CANNY1 = st.slider("Cannyé–¾å€¤1", 0, 255, 60, 1)
                CANNY2 = st.slider("Cannyé–¾å€¤2", 0, 255, 180, 1)
                HOUGH_THR = st.slider("Houghã—ãã„å€¤", 1, 200, 60, 1)
                MAX_GAP = st.slider("ç·šåˆ†ã®æœ€å¤§ã‚®ãƒ£ãƒƒãƒ—(px/ç¸®å°å¾Œ)", 0, 50, 10, 1)
                RESIZE_MAX_W = st.slider("æ¤œå‡ºæ™‚ã®æœ€å¤§å¹…ï¼ˆé«˜é€ŸåŒ–ï¼‰", 320, 1920, 960, 10)
        else:
            POLE_CROP_FRACTION, ANG_TOL, MIN_LEN_RATIO = 0.33, 25, 0.35
            CANNY1, CANNY2, HOUGH_THR, MAX_GAP, RESIZE_MAX_W = 60, 180, 60, 10, 960
    else:
        # ç”»åƒãƒ¢ãƒ¼ãƒ‰ã«ã‚‚é©ç”¨ã—ãŸã„å ´åˆã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        APPLY_IMAGE_CROP = st.checkbox("ç”»åƒã«ã‚‚åˆ‡ã‚Šå‡ºã—ã‚’é©ç”¨ã™ã‚‹", value=False)
        if APPLY_IMAGE_CROP:
            CROP_MODE_IMAGE = st.radio("ç”»åƒã®åˆ‡ã‚Šå‡ºã—æ–¹æ³•", ["ä¸­å¤®", "ãƒãƒ¼ãƒ«è‡ªå‹•", "ãƒãƒ¼ãƒ«è‡ªå‹•ï¼‹å›è»¢è£œæ­£"], index=2)
            if CROP_MODE_IMAGE == "ä¸­å¤®":
                IMG_CENTER_FRACTION = st.slider("ä¸­å¤®ãƒˆãƒªãƒŸãƒ³ã‚°å¹…ï¼ˆæ¨ªå‰²åˆ/ç”»åƒï¼‰", 0.10, 1.00, 0.33, 0.01)
            elif CROP_MODE_IMAGE == "ãƒãƒ¼ãƒ«è‡ªå‹•":
                IMG_POLE_FRACTION = st.slider("ãƒãƒ¼ãƒ«åˆ‡ã‚Šå‡ºã—å¹…ï¼ˆæ¨ªå‰²åˆ/ç”»åƒï¼‰", 0.10, 1.00, 0.33, 0.01)
            else:
                IMG_POLE_FRACTION = st.slider("ãƒãƒ¼ãƒ«åˆ‡ã‚Šå‡ºã—å¹…ï¼ˆæ¨ªå‰²åˆ/ç”»åƒï¼‰", 0.10, 1.00, 0.33, 0.01)
                if cv2 is None:
                    st.warning("å›è»¢è£œæ­£ã«ã¯ OpenCV ãŒå¿…è¦ã§ã™ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒç„¡ã„å ´åˆã¯å›è»¢è£œæ­£ãªã—ã§å‡¦ç†ã—ã¾ã™ã€‚")
        else:
            CROP_MODE_IMAGE = "ä¸­å¤®"
            IMG_CENTER_FRACTION = 1.0
            IMG_POLE_FRACTION = 0.33

# -------- ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆé¸æŠå¼ï¼‰ --------
candidate_model_dirs = walk_dirs_with_files(SEARCH_ROOTS, MODEL_EXTS, max_depth=2, limit=200)
if not candidate_model_dirs:
    st.error("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.pth/.pt/.binï¼‰ã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()
default_model_idx = 0
for i, d in enumerate(candidate_model_dirs):
    if os.path.normpath(d) in (os.path.normpath("saved_models"), os.path.normpath("./saved_models")):
        default_model_idx = i; break
model_dir = st.selectbox("ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é¸æŠã—ã¦ãã ã•ã„", candidate_model_dirs, index=default_model_idx)

model_candidates = sorted([f for f in os.listdir(model_dir) if f.lower().endswith(MODEL_EXTS)])
if not model_candidates:
    st.error("âŒ é¸æŠã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.pth/.pt/.binï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()
model_file = st.selectbox("ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", model_candidates, index=0)
model_path = os.path.join(model_dir, model_file)

try:
    model = load_model(model_path, num_classes=len(class_names))
except Exception as e:
    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()

# -------- ç”»åƒorå‹•ç”»ã®é¸æŠUI --------
def list_files_with_ext(dirpath, exts):
    return sorted([f for f in os.listdir(dirpath) if f.lower().endswith(exts)])

def format_time_label(seconds: float) -> str:
    if seconds < 0: seconds = 0.0
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = seconds - (h*3600 + m*60)
    if h > 0:
        return f"{h:d}:{m:02d}:{s:04.1f}"
    else:
        return f"{m:d}:{s:04.1f}"

def extract_frames_from_video(video_path: str, every_sec: float = 2.0, max_frames: int | None = None, crop_fraction: float = 1.0):
    """OpenCVã§å‹•ç”»ã‹ã‚‰ä¸€å®šç§’é–“éš”ã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º â†’ [(PIL.Image, seconds), ...] ã‚’è¿”ã™
       crop_fraction<1ã®æ™‚ã¯ä¸­å¤®ã‚’ãã®å‰²åˆã§æ¨ªæ–¹å‘ãƒˆãƒªãƒŸãƒ³ã‚°ï¼ˆæ—©æœŸã‚¯ãƒ­ãƒƒãƒ—ï¼‰ã€‚"""
    if cv2 is None:
        raise RuntimeError("OpenCV(cv2)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install opencv-python")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"å‹•ç”»ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps <= 0:
        fps = 30.0
    next_sample_ms = 0.0
    frames = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        pos_ms = cap.get(cv2.CAP_PROP_POS_MSEC)
        if pos_ms is None or pos_ms <= 0:
            frame_idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            pos_ms = (frame_idx / fps) * 1000.0

        if pos_ms + 1e-6 >= next_sample_ms:
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(rgb)
            if crop_fraction < 0.999:
                pil_img = crop_center_horizontal_fraction(pil_img, crop_fraction)
            frames.append((pil_img, pos_ms / 1000.0))
            next_sample_ms += every_sec * 1000.0
            if max_frames is not None and len(frames) >= max_frames:
                break

    cap.release()
    return frames

regression_results = []

if INPUT_MODE.startswith("ç”»åƒ"):
    # -------- ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ï¼ˆé¸æŠå¼ï¼‰ --------
    candidate_image_dirs = walk_dirs_with_files(SEARCH_ROOTS, IMAGE_EXTS, max_depth=2, limit=200)
    if not candidate_image_dirs:
        st.error("âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()
    default_image_idx = 0
    for i, d in enumerate(candidate_image_dirs):
        if os.path.normpath(d) in (os.path.normpath("images"), os.path.normpath("./images"),
                                   os.path.normpath("sample"), os.path.normpath("./sample"),
                                   os.path.normpath("samples"), os.path.normpath("./samples")):
            default_image_idx = i; break
    image_dir = st.selectbox("ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„", candidate_image_dirs, index=default_image_idx)

    image_files = list_files_with_ext(image_dir, IMAGE_EXTS)
    if not image_files:
        st.warning("âš ï¸ é¸æŠã—ãŸãƒ•ã‚©ãƒ«ãƒ€ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    default_pick = image_files
    selected_images = st.multiselect("è¡¨ç¤ºã™ã‚‹ç”»åƒã‚’é¸ã‚“ã§ãã ã•ã„", image_files, default=default_pick)
    if not selected_images:
        st.info("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ===== ç”»åƒå‡¦ç†ãƒ«ãƒ¼ãƒ— =====
    DISPLAY_ORDER_INTERNAL = ["Corrosion", "no-Corrosion", "base"]
    DISPLAY_ORDER_CANON = [norm_label(x) for x in DISPLAY_ORDER_INTERNAL]
    norm_to_idx = {norm_label(lbl): i for i, lbl in enumerate(class_names)}

    for image_file in selected_images:
        image_path = os.path.join(image_dir, image_file)
        try:
            image = Image.open(image_path).convert("RGB")

            # å¿…è¦ãªã‚‰åˆ‡ã‚Šå‡ºã—ï¼ˆç”»åƒãƒ¢ãƒ¼ãƒ‰ï¼‰
            if 'APPLY_IMAGE_CROP' in locals() and APPLY_IMAGE_CROP:
                if CROP_MODE_IMAGE == "ä¸­å¤®":
                    image = crop_center_horizontal_fraction(image, IMG_CENTER_FRACTION)
                elif CROP_MODE_IMAGE == "ãƒãƒ¼ãƒ«è‡ªå‹•":
                    cropped = crop_to_pole(
                        image, width_fraction=IMG_POLE_FRACTION,
                        angle_tol_deg=25.0, min_length_ratio=0.35,
                        canny1=60, canny2=180, hough_thresh=60, max_line_gap_px=10, resize_max_w=960
                    )
                    if cropped is not None:
                        image = cropped
                else:  # ãƒãƒ¼ãƒ«è‡ªå‹•ï¼‹å›è»¢è£œæ­£
                    cropped = crop_to_pole_deskew(
                        image, width_fraction=IMG_POLE_FRACTION,
                        angle_tol_deg=25.0, min_length_ratio=0.35,
                        canny1=60, canny2=180, hough_thresh=60, max_line_gap_px=10, resize_max_w=960
                    ) if cv2 is not None else None
                    if cropped is not None:
                        image = cropped
                    elif cv2 is None:
                        # OpenCVãªã—ãªã‚‰å›è»¢è£œæ­£ãªã—ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        cropped2 = crop_to_pole(
                            image, width_fraction=IMG_POLE_FRACTION,
                            angle_tol_deg=25.0, min_length_ratio=0.35,
                            canny1=60, canny2=180, hough_thresh=60, max_line_gap_px=10, resize_max_w=960
                        )
                        if cropped2 is not None:
                            image = cropped2

            logits, class_scores, pred_class_idx, reg_value = infer_image(model, image)

            # ãƒ”ãƒ¼ã‚¯ï¼ˆsoftmaxæœ€å¤§ï¼‰ãŒ corrosion / new ã‹ã©ã†ã‹
            top_idx = int(np.argmax(class_scores))
            idx_cor = norm_to_idx["corrosion"]
            is_corrosion_top = (top_idx == idx_cor)
            # â˜… new=base ãŒæœ€å¤§ãªã‚‰åŠ£åŒ–åº¦ã‚¹ã‚³ã‚¢ã‚’ 0 ã«è£œæ­£
            idx_new = norm_to_idx["base"]
            if top_idx == idx_new:
                reg_value = 0.0

            pred_internal = class_names[pred_class_idx]
            pred_display = to_display_name(norm_label(pred_internal))
            is_corrosion = (pred_display.lower() == "corrosion")

            # ã‚¿ã‚¤ãƒ«ç”»åƒ
            tile_img = fit_square_canvas(image, TILE_SIZE, bg=(255, 255, 255), inner_ratio=IMAGE_SHRINK)
            if is_corrosion:
                tile_img = draw_red_border(tile_img, width=4, color=(255, 0, 0))

            # åˆ†é¡ã‚¹ã‚³ã‚¢
            ordered_scores, ordered_labels_display = [], []
            for canon in DISPLAY_ORDER_CANON:
                idx = norm_to_idx.get(canon, None)
                score = class_scores[idx] if idx is not None else 0.0
                disp = to_display_name(canon)
                ordered_scores.append(float(score))
                ordered_labels_display.append(disp)
            fig_cls = make_square_bar_figure(
                ordered_labels_display, ordered_scores, size_px=TILE_SIZE,
                title="åˆ†é¡ã‚¹ã‚³ã‚¢", red_border=is_corrosion
            )

            # å›å¸°ï¼ˆcorrosionãŒãƒˆãƒƒãƒ—ã§ãªã„å ´åˆã¯ã‚°ãƒ¬ãƒ¼ãƒãƒƒãƒï¼‰
            apply_gray_hatch = (not is_corrosion_top)
            reg_title = "åŠ£åŒ–åº¦ã‚¹ã‚³ã‚¢ (0-1)" if "åŠ£åŒ–åº¦" in regression_mode else "è…é£Ÿé¢ç©ç‡ (0-1)"
            fig_reg = make_square_bar_figure(
                ["åŠ£åŒ–åº¦" if "åŠ£åŒ–åº¦" in regression_mode else "é¢ç©ç‡"], [reg_value], size_px=TILE_SIZE,
                title=reg_title, red_border=is_corrosion,
                hatch_pattern=("////" if apply_gray_hatch else None),
                hatch_facecolor=((0.85, 0.85, 0.85) if apply_gray_hatch else None)
            )

            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            if layout_mode.startswith("3åˆ—"):
                c1, c2, c3 = st.columns([1, 1, 1], gap="medium", vertical_alignment="top")
                with c1:
                    st.markdown(f"**ğŸ“· {image_file}**")
                    st.image(tile_img, caption=f"Predicted: {pred_display}", use_container_width=True)
                with c2:
                    st.pyplot(fig_cls, clear_figure=True, use_container_width=True)
                with c3:
                    st.pyplot(fig_reg, clear_figure=True, use_container_width=True)
            else:
                left, right = st.columns([1, 1], gap="large", vertical_alignment="top")
                with left:
                    st.markdown(f"**ğŸ“· {image_file}**")
                    st.image(tile_img, caption=f"Predicted: {pred_display}", use_container_width=True)
                    st.pyplot(fig_cls, clear_figure=True, use_container_width=True)
                with right:
                    st.pyplot(fig_reg, clear_figure=True, use_container_width=True)

            # å¾Œå‡¦ç†
            plt.close(fig_cls); plt.close(fig_reg)
            regression_results.append((image_file, float(reg_value)))
            st.markdown('<div class="section-gap"></div>', unsafe_allow_html=True)

        except Exception as e:
            st.error(f"{image_file} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

else:
    # -------- å‹•ç”»ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆé¸æŠå¼ï¼‰ --------
    if cv2 is None:
        st.stop()

    candidate_video_dirs = walk_dirs_with_files(VIDEO_SEARCH_ROOTS, VIDEO_EXTS, max_depth=2, limit=200)
    if not candidate_video_dirs:
        st.error("âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmp4ç­‰ï¼‰ã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    default_video_idx = 0
    for i, d in enumerate(candidate_video_dirs):
        if os.path.normpath(d) in (os.path.normpath("movie"), os.path.normpath("./movie"),
                                   os.path.normpath("movies"), os.path.normpath("./movies")):
            default_video_idx = i; break
    video_dir = st.selectbox("å‹•ç”»ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„", candidate_video_dirs, index=default_video_idx)

    video_files = list_files_with_ext(video_dir, VIDEO_EXTS)
    video_files = sorted(video_files, key=lambda x: (not x.lower().endswith(".mp4"), x.lower()))
    if not video_files:
        st.warning("âš ï¸ é¸æŠã—ãŸãƒ•ã‚©ãƒ«ãƒ€ã«å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmp4ç­‰ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    default_pick = [f for f in video_files if f.lower().endswith(".mp4")] or video_files
    selected_videos = st.multiselect("å‡¦ç†ã™ã‚‹å‹•ç”»ã‚’é¸ã‚“ã§ãã ã•ã„", video_files, default=default_pick)
    if not selected_videos:
        st.info("å‹•ç”»ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ===== å‹•ç”»â†’ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºâ†’å‡¦ç†ãƒ«ãƒ¼ãƒ— =====
    DISPLAY_ORDER_INTERNAL = ["Corrosion", "no-Corrosion", "base"]
    DISPLAY_ORDER_CANON = [norm_label(x) for x in DISPLAY_ORDER_INTERNAL]
    norm_to_idx = {norm_label(lbl): i for i, lbl in enumerate(class_names)}

    for video_file in selected_videos:
        video_path = os.path.join(video_dir, video_file)
        try:
            with st.spinner(f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºä¸­: {video_file}ï¼ˆ{FRAME_EVERY_SEC:.1f}sé–“éš”, æœ€å¤§{MAX_FRAMES_PER_VIDEO}æš, åˆ‡ã‚Šå‡ºã—:{CROP_MODE_VIDEO}ï¼‰"):
                frames = extract_frames_from_video(
                    video_path,
                    every_sec=FRAME_EVERY_SEC,
                    max_frames=int(MAX_FRAMES_PER_VIDEO),
                    crop_fraction=float(CENTER_CROP_FRACTION)  # ä¸­å¤®é¸æŠæ™‚ã®ã¿<1.0ã«ãªã‚‹
                )
            if not frames:
                st.warning(f"âš ï¸ æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ ãªã—: {video_file}")
                continue

            for pil_img, sec in frames:
                # â˜… ãƒãƒ¼ãƒ«è‡ªå‹• or å›è»¢è£œæ­£ä»˜ãåˆ‡ã‚Šå‡ºã—
                if CROP_MODE_VIDEO == "ãƒãƒ¼ãƒ«è‡ªå‹•":
                    cropped = crop_to_pole(
                        pil_img, width_fraction=POLE_CROP_FRACTION,
                        angle_tol_deg=ANG_TOL, min_length_ratio=MIN_LEN_RATIO,
                        canny1=CANNY1, canny2=CANNY2, hough_thresh=HOUGH_THR,
                        max_line_gap_px=MAX_GAP, resize_max_w=RESIZE_MAX_W
                    )
                    if cropped is not None:
                        pil_img = cropped
                    else:
                        pil_img = crop_center_horizontal_fraction(pil_img, POLE_CROP_FRACTION)
                elif CROP_MODE_VIDEO == "ãƒãƒ¼ãƒ«è‡ªå‹•ï¼‹å›è»¢è£œæ­£":
                    cropped = crop_to_pole_deskew(
                        pil_img, width_fraction=POLE_CROP_FRACTION,
                        angle_tol_deg=ANG_TOL, min_length_ratio=MIN_LEN_RATIO,
                        canny1=CANNY1, canny2=CANNY2, hough_thresh=HOUGH_THR,
                        max_line_gap_px=MAX_GAP, resize_max_w=RESIZE_MAX_W
                    )
                    if cropped is not None:
                        pil_img = cropped
                    else:
                        # æ¤œå‡ºå¤±æ•—æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        pil_img = crop_center_horizontal_fraction(pil_img, POLE_CROP_FRACTION)
                # ãã‚Œä»¥å¤–ï¼ˆãªã—/ä¸­å¤®ï¼‰ã¯ãã®ã¾ã¾

                display_id = f"{video_file} @ {format_time_label(sec)}"

                logits, class_scores, pred_class_idx, reg_value = infer_image(model, pil_img)

                # ãƒ”ãƒ¼ã‚¯ï¼ˆsoftmaxæœ€å¤§ï¼‰ãŒ corrosion / new ã‹
                top_idx = int(np.argmax(class_scores))
                idx_cor = norm_to_idx["corrosion"]
                is_corrosion_top = (top_idx == idx_cor)
                # â˜… new=base ãŒæœ€å¤§ãªã‚‰åŠ£åŒ–åº¦ã‚¹ã‚³ã‚¢ã‚’ 0 ã«è£œæ­£
                idx_new = norm_to_idx["base"]
                if top_idx == idx_new:
                    reg_value = 0.0

                pred_internal = class_names[pred_class_idx]
                pred_display = to_display_name(norm_label(pred_internal))
                is_corrosion = (pred_display.lower() == "corrosion")

                # ã‚¿ã‚¤ãƒ«ç”»åƒ
                tile_img = fit_square_canvas(pil_img, TILE_SIZE, bg=(255, 255, 255), inner_ratio=IMAGE_SHRINK)
                if is_corrosion:
                    tile_img = draw_red_border(tile_img, width=4, color=(255, 0, 0))

                # åˆ†é¡ã‚¹ã‚³ã‚¢
                ordered_scores, ordered_labels_display = [], []
                for canon in DISPLAY_ORDER_CANON:
                    idx = norm_to_idx.get(canon, None)
                    score = class_scores[idx] if idx is not None else 0.0
                    disp = to_display_name(canon)
                    ordered_scores.append(float(score))
                    ordered_labels_display.append(disp)
                fig_cls = make_square_bar_figure(
                    ordered_labels_display, ordered_scores, size_px=TILE_SIZE,
                    title="åˆ†é¡ã‚¹ã‚³ã‚¢", red_border=is_corrosion
                )

                # å›å¸°ï¼ˆcorrosionãŒãƒˆãƒƒãƒ—ã§ãªã„å ´åˆã¯ã‚°ãƒ¬ãƒ¼ãƒãƒƒãƒï¼‰
                apply_gray_hatch = (not is_corrosion_top)
                reg_title = "åŠ£åŒ–åº¦ã‚¹ã‚³ã‚¢ (0-1)" if "åŠ£åŒ–åº¦" in regression_mode else "è…é£Ÿé¢ç©ç‡ (0-1)"
                fig_reg = make_square_bar_figure(
                    ["åŠ£åŒ–åº¦" if "åŠ£åŒ–åº¦" in regression_mode else "é¢ç©ç‡"], [reg_value], size_px=TILE_SIZE,
                    title=reg_title, red_border=is_corrosion,
                    hatch_pattern=("////" if apply_gray_hatch else None),
                    hatch_facecolor=((0.85, 0.85, 0.85) if apply_gray_hatch else None)
                )

                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
                if layout_mode.startswith("3åˆ—"):
                    c1, c2, c3 = st.columns([1, 1, 1], gap="medium", vertical_alignment="top")
                    with c1:
                        st.markdown(f"**ğŸ {display_id}**")
                        st.image(tile_img, caption=f"Predicted: {pred_display}", use_container_width=True)
                    with c2:
                        st.pyplot(fig_cls, clear_figure=True, use_container_width=True)
                    with c3:
                        st.pyplot(fig_reg, clear_figure=True, use_container_width=True)
                else:
                    left, right = st.columns([1, 1], gap="large", vertical_alignment="top")
                    with left:
                        st.markdown(f"**ğŸ {display_id}**")
                        st.image(tile_img, caption=f"Predicted: {pred_display}", use_container_width=True)
                        st.pyplot(fig_cls, clear_figure=True, use_container_width=True)
                    with right:
                        st.pyplot(fig_reg, clear_figure=True, use_container_width=True)

                plt.close(fig_cls); plt.close(fig_reg)
                regression_results.append((display_id, float(reg_value)))
                st.markdown('<div class="section-gap"></div>', unsafe_allow_html=True)

        except Exception as e:
            st.error(f"{video_file} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
